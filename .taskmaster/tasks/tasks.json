{
  "master": {
    "tasks": [
      {
        "id": "11",
        "title": "Fix ESLint Errors Blocking Builds",
        "description": "Resolve the three linting errors that are preventing production deployment to npm and causing CI/CD failures.",
        "details": "Address the following ESLint errors:\n1. `packages/pkf-init/src/migration/worker.ts:614:63` - Remove or utilize the unused parameter 'schema'\n2. `packages/pkf-init/src/stages/schema-design.ts:390:11` - Remove or utilize the unused variable 'patterns'\n3. `packages/pkf-init/src/stages/schema-design.ts:396:38` - Fix regex spacing issue (no-regex-spaces)\n\nImplementation steps:\n- For the unused parameter, either remove it from the function signature or use it in the function body\n- For the unused variable, either remove the declaration or use it in subsequent code\n- For the regex spacing issue, replace multiple spaces with a quantifier (e.g., change '  ' to ' {2}')\n- Run ESLint locally to verify fixes: `npx eslint packages/pkf-init/src/`\n- Ensure build passes with zero errors: `npm run build`",
        "testStrategy": "1. Run ESLint on the codebase to verify no errors remain\n2. Execute the build process to confirm it completes successfully\n3. Run existing tests to ensure functionality is preserved\n4. Verify CI/CD pipeline passes with the changes",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-04T23:02:18.792Z"
      },
      {
        "id": "12",
        "title": "Fix Race Condition in Lock Manager",
        "description": "Resolve the TOCTOU (Time-of-Check Time-of-Use) vulnerability in the lock manager that allows two processes to corrupt locks simultaneously.",
        "details": "Implement atomic file operations using fs.open with O_EXCL flag to ensure exclusive lock creation:\n\n```typescript\n// Replace current lock creation with atomic operation\nimport fs from 'fs/promises';\nimport { constants } from 'fs';\n\nasync function createLock(lockPath: string): Promise<boolean> {\n  try {\n    // Use O_EXCL flag to ensure atomic creation\n    const fileHandle = await fs.open(lockPath, constants.O_CREAT | constants.O_EXCL | constants.O_WRONLY);\n    await fileHandle.write(JSON.stringify({ pid: process.pid, timestamp: Date.now() }));\n    await fileHandle.close();\n    return true;\n  } catch (error) {\n    if (error.code === 'EEXIST') {\n      // Lock already exists\n      return false;\n    }\n    throw error; // Rethrow unexpected errors\n  }\n}\n\nasync function releaseLock(lockPath: string): Promise<void> {\n  try {\n    await fs.unlink(lockPath);\n  } catch (error) {\n    if (error.code !== 'ENOENT') { // Ignore if file doesn't exist\n      throw error;\n    }\n  }\n}\n```\n\nEnsure backward compatibility with existing lock files by adding a function to check and validate existing locks.",
        "testStrategy": "1. Create unit tests that simulate concurrent lock attempts\n2. Verify that only one process can acquire a lock at a time\n3. Test lock release functionality\n4. Test backward compatibility with existing lock files\n5. Create integration tests with multiple processes attempting to acquire locks simultaneously\n6. Verify no data corruption occurs under high concurrency",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-04T23:05:14.685Z"
      },
      {
        "id": "13",
        "title": "Remove Production Debug Logs",
        "description": "Remove or gate all debug console statements behind a verbose flag to ensure clean production output.",
        "details": "1. Implement a structured logger to replace direct console.error calls:\n\n```typescript\n// Create a structured logger module (src/utils/logger.ts)\nimport chalk from 'chalk';\n\nexport enum LogLevel {\n  ERROR = 0,\n  WARN = 1,\n  INFO = 2,\n  DEBUG = 3,\n  TRACE = 4\n}\n\nexport class Logger {\n  private static instance: Logger;\n  private level: LogLevel = LogLevel.INFO; // Default level\n\n  private constructor() {}\n\n  static getInstance(): Logger {\n    if (!Logger.instance) {\n      Logger.instance = new Logger();\n    }\n    return Logger.instance;\n  }\n\n  setLevel(level: LogLevel): void {\n    this.level = level;\n  }\n\n  error(message: string, ...args: any[]): void {\n    if (this.level >= LogLevel.ERROR) {\n      console.error(chalk.red(`ERROR: ${message}`), ...args);\n    }\n  }\n\n  warn(message: string, ...args: any[]): void {\n    if (this.level >= LogLevel.WARN) {\n      console.warn(chalk.yellow(`WARN: ${message}`), ...args);\n    }\n  }\n\n  info(message: string, ...args: any[]): void {\n    if (this.level >= LogLevel.INFO) {\n      console.info(chalk.blue(`INFO: ${message}`), ...args);\n    }\n  }\n\n  debug(message: string, ...args: any[]): void {\n    if (this.level >= LogLevel.DEBUG) {\n      console.debug(chalk.gray(`DEBUG: ${message}`), ...args);\n    }\n  }\n\n  trace(message: string, ...args: any[]): void {\n    if (this.level >= LogLevel.TRACE) {\n      console.debug(chalk.gray(`TRACE: ${message}`), ...args);\n    }\n  }\n}\n```\n\n2. Replace all console.error statements in orchestrator with the new logger\n3. Add a verbose flag to CLI options that sets the log level\n4. Ensure production output is clean by default (INFO level or lower)\n5. Update all relevant files to use the new logger instead of console methods",
        "testStrategy": "1. Create unit tests for the logger with different log levels\n2. Verify that debug messages are suppressed at default log level\n3. Test CLI with and without verbose flag to confirm output differences\n4. Run integration tests to ensure all debug output is properly gated\n5. Verify production output is clean with no debug messages",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-04T23:10:04.913Z"
      },
      {
        "id": "14",
        "title": "Implement Comprehensive Unit Tests",
        "description": "Add unit tests for core workflow stages to improve code quality, maintainability, and confidence in changes.",
        "details": "Create unit tests for the following modules that currently lack unit test coverage:\n\n1. `src/stages/analysis.ts`\n2. `src/stages/schema-design.ts`\n3. `src/stages/implementation.ts`\n4. `src/stages/migration.ts`\n5. `src/migration/worker.ts`\n6. `src/migration/executor.ts`\n7. `src/agents/orchestrator.ts`\n8. `src/api/anthropic-client.ts`\n\nImplementation approach:\n- Use Vitest for test framework\n- Create mocks for external dependencies (API calls, file I/O)\n- Focus on testing public methods first\n- Test error handling paths\n- Aim for 70%+ code coverage\n\nExample test structure for a stage class:\n\n```typescript\nimport { describe, it, expect, vi, beforeEach } from 'vitest';\nimport { AnalysisStage } from '../src/stages/analysis';\n\n// Mock dependencies\nvi.mock('fs/promises', () => ({\n  readFile: vi.fn(),\n  writeFile: vi.fn(),\n  readdir: vi.fn()\n}));\n\nvi.mock('../src/api/anthropic-client', () => ({\n  AnthropicClient: vi.fn().mockImplementation(() => ({\n    analyze: vi.fn().mockResolvedValue({ result: 'mocked analysis' })\n  }))\n}));\n\ndescribe('AnalysisStage', () => {\n  let analysisStage;\n  \n  beforeEach(() => {\n    analysisStage = new AnalysisStage({\n      projectRoot: '/mock/path',\n      config: { /* mock config */ }\n    });\n  });\n  \n  it('should initialize with correct properties', () => {\n    expect(analysisStage.projectRoot).toBe('/mock/path');\n  });\n  \n  it('should analyze files correctly', async () => {\n    // Setup mocks\n    // Test implementation\n    // Assert results\n  });\n  \n  it('should handle errors gracefully', async () => {\n    // Setup error condition\n    // Test error handling\n    // Assert error is handled correctly\n  });\n});\n```",
        "testStrategy": "1. Create test files for each untested module\n2. Use mocks to isolate units from external dependencies\n3. Test happy paths, error paths, and edge cases\n4. Run tests with coverage reporting: `npx vitest run --coverage`\n5. Verify coverage meets 70%+ target for core stages\n6. Ensure all tests pass consistently\n7. Add tests to CI pipeline to prevent regressions",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T05:55:36.435Z"
      },
      {
        "id": "15",
        "title": "Externalize Template Strings",
        "description": "Extract hardcoded template strings from the migration worker to external files for improved customizability and maintainability.",
        "details": "1. Create a template directory structure:\n```\ntemplates/\n  readme.md\n  guide.md\n  changelog.md\n  todo.md\n  issues.md\n  ...\n```\n\n2. Extract template strings from migration worker (lines 663-696) to these files\n\n3. Implement template loading mechanism:\n```typescript\nimport fs from 'fs/promises';\nimport path from 'path';\n\nexport class TemplateManager {\n  private templateDir: string;\n  private customTemplateDir: string | null;\n  private templates: Map<string, string> = new Map();\n\n  constructor(options: { \n    templateDir?: string;\n    customTemplateDir?: string;\n  }) {\n    this.templateDir = options.templateDir || path.join(__dirname, '../templates');\n    this.customTemplateDir = options.customTemplateDir || null;\n  }\n\n  async loadTemplate(templateName: string): Promise<string> {\n    // Return cached template if available\n    if (this.templates.has(templateName)) {\n      return this.templates.get(templateName)!;\n    }\n\n    // Try loading from custom directory first\n    if (this.customTemplateDir) {\n      try {\n        const customPath = path.join(this.customTemplateDir, `${templateName}.md`);\n        const template = await fs.readFile(customPath, 'utf-8');\n        this.templates.set(templateName, template);\n        return template;\n      } catch (error) {\n        // Fall back to default if custom template not found\n        if (error.code !== 'ENOENT') throw error;\n      }\n    }\n\n    // Load from default template directory\n    const defaultPath = path.join(this.templateDir, `${templateName}.md`);\n    const template = await fs.readFile(defaultPath, 'utf-8');\n    this.templates.set(templateName, template);\n    return template;\n  }\n\n  async getAvailableTemplates(): Promise<string[]> {\n    const files = await fs.readdir(this.templateDir);\n    return files\n      .filter(file => file.endsWith('.md'))\n      .map(file => file.replace(/\\.md$/, ''));\n  }\n}\n```\n\n4. Update migration worker to use the template manager\n5. Add CLI option for custom template directory\n6. Document template customization in user guide",
        "testStrategy": "1. Create unit tests for TemplateManager class\n2. Verify default templates load correctly\n3. Test custom template override functionality\n4. Ensure backward compatibility with existing code\n5. Test with various template formats and sizes\n6. Verify error handling for missing or invalid templates",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T02:32:44.899Z"
      },
      {
        "id": "16",
        "title": "Enhance Error Handling for Parallel Operations",
        "description": "Improve error handling in parallel operations to prevent complete failure on partial errors and provide graceful degradation.",
        "status": "done",
        "dependencies": [
          "13"
        ],
        "priority": "medium",
        "details": "**COMPLETED IMPLEMENTATION**\n\nEnhanced error handling for parallel operations has been fully implemented in the AgentOrchestrator class at `packages/pkf-init/src/agents/orchestrator.ts`.\n\n## Implementation Summary\n\n### 1. Enhanced `parallelAgentTasks` Method (lines 371-445)\n\nModified to handle partial failures gracefully:\n\n```typescript\nasync parallelAgentTasks(\n  tasks: Array<{ agentName: string; prompt: string; id?: string }>,\n  concurrency: number = 5,\n  onProgress?: (completed: number, total: number, lastId?: string) => void\n): Promise<Array<AgentResult & { id?: string }>>\n```\n\nKey improvements:\n- Added try-catch around each task execution\n- Track both failed and completed counts\n- Log warnings for individual task failures\n- Summary logging with success/failure counts\n- Continue execution even if some tasks fail\n- Return all results (successful and failed) in original order\n\n### 2. New Generic `executeParallelTasks` Utility Method (lines 457-490)\n\n```typescript\nasync executeParallelTasks<T>(\n  tasks: Array<() => Promise<T>>\n): Promise<{\n  results: Array<T | undefined>;\n  errors: Array<{ index: number; error: Error } | undefined>;\n  successCount: number;\n  failureCount: number;\n}>\n```\n\nFeatures:\n- Accepts array of async task functions\n- Returns object with results, errors, successCount, failureCount\n- Separates successful results from errors with indices\n- Provides fine-grained control over partial failure handling\n\n### 3. Comprehensive Logging\n\n- Warn-level logs for individual task failures\n- Summary logging with success/failure counts at end\n- Error-level logs for unexpected exceptions\n- Debug-level logs for all-success scenarios\n\n## Files Modified\n\n- `packages/pkf-init/src/agents/orchestrator.ts` - Enhanced parallel execution methods\n- `packages/pkf-init/tests/agents/orchestrator.test.ts` - Comprehensive test suite (13 tests)\n\n## Test Coverage\n\nThe test suite covers:\n1. All success scenarios\n2. Partial failure scenarios (mixed success/failure)\n3. All failure scenarios\n4. Unexpected exception handling (non-Error throws)\n5. Result order preservation regardless of completion order\n6. Progress callback accuracy\n7. Graceful degradation when agents are unavailable\n8. Concurrency control with mixed results\n9. Error index tracking",
        "testStrategy": "**VERIFICATION COMPLETED**\n\nComprehensive test suite implemented at `packages/pkf-init/tests/agents/orchestrator.test.ts` with 13 tests:\n\n### executeParallelTasks Tests (8 tests):\n1. Collects all results when all tasks succeed\n2. Collects partial results when some tasks fail\n3. Continues execution after failures\n4. Handles all tasks failing\n5. Handles non-Error exceptions (converts to Error instances)\n6. Maintains result order regardless of completion order\n7. Provides error indices correctly\n\n### parallelAgentTasks Tests (5 tests):\n8. Reports partial success correctly with task IDs\n9. Catches unexpected errors in parallel tasks\n10. Calls progress callback with correct counts\n11. Maintains task order with concurrency control\n12. Handles mixed success and failure with concurrency\n\n### Graceful Degradation Tests (1 test):\n13. Returns partial results when some agents are unavailable\n\n**All tests passing. TypeScript compilation successful.**",
        "subtasks": [],
        "updatedAt": "2026-01-05T02:27:29.973Z"
      },
      {
        "id": "17",
        "title": "Implement Configurable Constants",
        "description": "Make hardcoded magic numbers configurable via configuration file and environment variables for improved flexibility and customization.",
        "details": "1. Create a configuration system:\n\n```typescript\n// src/config/index.ts\nimport fs from 'fs/promises';\nimport path from 'path';\nimport yaml from 'js-yaml';\n\ninterface PKFConfig {\n  analysis: {\n    maxParallelInspections: number;\n  };\n  orchestration: {\n    maxIterations: number;\n    retryAttempts: number;\n    retryDelayMs: number;\n  };\n  planning: {\n    avgOutputTokensPerDoc: number;\n  };\n  api: {\n    timeout: number;\n    maxRetries: number;\n    retryDelayMs: number;\n  };\n}\n\nconst DEFAULT_CONFIG: PKFConfig = {\n  analysis: {\n    maxParallelInspections: 3,\n  },\n  orchestration: {\n    maxIterations: 5,\n    retryAttempts: 3,\n    retryDelayMs: 1000,\n  },\n  planning: {\n    avgOutputTokensPerDoc: 1000,\n  },\n  api: {\n    timeout: 60000,\n    maxRetries: 3,\n    retryDelayMs: 2000,\n  },\n};\n\nexport async function loadConfig(configPath?: string): Promise<PKFConfig> {\n  // Start with default config\n  const config = { ...DEFAULT_CONFIG };\n  \n  // Try to load from config file if provided\n  if (configPath) {\n    try {\n      const fileContent = await fs.readFile(configPath, 'utf-8');\n      const fileConfig = yaml.load(fileContent, { schema: yaml.JSON_SCHEMA }) as Partial<PKFConfig>;\n      mergeConfig(config, fileConfig);\n    } catch (error) {\n      if (error.code !== 'ENOENT') {\n        throw new Error(`Failed to load config from ${configPath}: ${error.message}`);\n      }\n    }\n  }\n  \n  // Override with environment variables\n  applyEnvironmentOverrides(config);\n  \n  return config;\n}\n\nfunction mergeConfig(target: PKFConfig, source: Partial<PKFConfig>): void {\n  // Deep merge implementation\n}\n\nfunction applyEnvironmentOverrides(config: PKFConfig): void {\n  // Apply environment variable overrides\n  if (process.env.PKF_MAX_PARALLEL_INSPECTIONS) {\n    config.analysis.maxParallelInspections = parseInt(process.env.PKF_MAX_PARALLEL_INSPECTIONS, 10);\n  }\n  // Add other environment variable mappings\n}\n```\n\n2. Update all relevant files to use the configuration values:\n   - Replace `MAX_PARALLEL_INSPECTIONS = 3` in analysis.ts\n   - Replace `DEFAULT_MAX_ITERATIONS = 5` in orchestrator.ts\n   - Replace `AVG_OUTPUT_TOKENS_PER_DOC = 1000` in planner.ts\n   - Replace retry attempts and delays in anthropic-client.ts\n\n3. Add CLI option to specify config file path\n4. Create documentation for configuration options",
        "testStrategy": "1. Create unit tests for config loading functionality\n2. Test merging of default values with file-based config\n3. Test environment variable overrides\n4. Verify each configurable constant is properly applied\n5. Test with invalid configuration values\n6. Ensure backward compatibility with existing behavior",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T02:32:18.770Z"
      },
      {
        "id": "18",
        "title": "Implement State Migration Strategy",
        "description": "Create a state version detection and migration system to handle version changes and prevent state cache corruption.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "**Implementation Complete** - State migration strategy fully implemented with all components.\n\n## Implemented Components\n\n### 1. Migration Module (`src/state/migration.ts`)\n- `migrateState(state, targetVersion)` - Migrates state from current version to target version\n- `validateState(state)` - Validates state structure against WorkflowState interface\n- `getAvailableMigrations()` - Returns list of available migration paths\n- `needsMigration(currentVersion, targetVersion)` - Checks if migration is needed\n- Uses `semver` package for robust version comparison\n- Supports migration path format: `'from-version-to-target-version'`\n\n### 2. WorkflowStateManager Integration (`src/state/workflow-state.ts`)\n- `load()` transparently migrates state to current version (1.0.0)\n- `save()` validates state before saving and stamps current version\n- Atomic save using temp file + rename pattern\n- Automatic version stamping on save\n\n### 3. State Schema Documentation (`docs/STATE_SCHEMA.md`)\n- Complete WorkflowState interface documentation\n- Stage-specific state schemas (AnalysisState, DesignState, etc.)\n- Version history section for tracking changes\n- Migration system documentation with examples\n- Troubleshooting guide for common errors\n\n### 4. Safety Features\n- Downgrade prevention (throws error if target < current)\n- Version validation using semver\n- State validation before save and after migration\n- Legacy state handling (assumes 1.0.0 for versionless state)\n- Migration path validation (throws if no path exists)\n\n### 5. Test Coverage\n- 20 migration-specific tests in `tests/state/migration.test.ts`\n- 7 integration tests in `tests/state/workflow-state.test.ts`\n- All 56 state-related tests passing\n- Tests cover: legacy state, version validation, migration sequences, downgrade prevention, field preservation",
        "testStrategy": "**Test Coverage Complete** - 56 state-related tests all passing:\n\n1. Migration unit tests (`tests/state/migration.test.ts` - 20 tests):\n   - Legacy state without version field handling\n   - Same-version no-op behavior\n   - Version-to-version migration (1.0.0 → 1.1.0)\n   - Downgrade prevention error handling\n   - Invalid version format detection\n   - Missing migration path detection\n   - Field preservation during migration\n   - validateState() with valid/invalid inputs\n   - needsMigration() helper function\n   - getAvailableMigrations() listing\n\n2. Integration tests (`tests/state/workflow-state.test.ts` - 7 state migration tests):\n   - Load and migrate legacy state without version\n   - Load old version state and migrate to current\n   - Invalid state structure rejection\n   - Save with current version stamping\n   - Invalid state save rejection\n   - Stage-specific state preservation during migration",
        "subtasks": [
          {
            "id": 1,
            "title": "Create state migration module with core migration functions",
            "description": "Implement src/state/migration.ts with migrateState(), validateState(), and helper functions",
            "dependencies": [],
            "details": "Created migration.ts with:\n- StateMigrationFunction type definition\n- migrations registry with 1.0.0-to-1.1.0 example\n- migrateState() with semver comparison, downgrade prevention, and path finding\n- validateState() checking all required WorkflowState fields\n- getAvailableMigrations() and needsMigration() helpers\n- parseMigrationKey() internal helper",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Integrate migration into WorkflowStateManager",
            "description": "Update workflow-state.ts to use migration system transparently on load/save",
            "dependencies": [],
            "details": "Updated WorkflowStateManager:\n- load() calls migrateState() after JSON parse, validates result\n- save() validates state before writing, stamps STATE_VERSION\n- STATE_VERSION constant (1.0.0) controls current version\n- Proper error handling for migration failures",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Add semver dependency for version comparison",
            "description": "Install @types/semver and semver package for robust version handling",
            "dependencies": [],
            "details": "Added semver and @types/semver to package.json dependencies. Used for:\n- semver.valid() - version format validation\n- semver.eq() - equality comparison\n- semver.gt() - greater-than for downgrade detection\n- semver.lte()/gte() - migration path filtering\n- semver.compare() - migration ordering",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Create comprehensive test suite for migration system",
            "description": "Add tests/state/migration.test.ts with 20+ tests covering all migration scenarios",
            "dependencies": [],
            "details": "Created test suite covering:\n- Legacy state handling (no version field)\n- Same-version passthrough\n- Version migration (1.0.0 → 1.1.0)\n- Downgrade prevention errors\n- Invalid version format errors\n- Missing migration path errors\n- Field preservation during migration\n- validateState() edge cases\n- Helper function behavior",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add integration tests for WorkflowStateManager migration",
            "description": "Add state migration tests to workflow-state.test.ts verifying end-to-end behavior",
            "dependencies": [],
            "details": "Added 7 integration tests:\n- Legacy state migration on load\n- Old version migration to current\n- Invalid state structure rejection\n- Version stamping on save\n- Invalid state save rejection\n- Stage-specific state preservation\n- Checkpoint preservation through migration",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Document state schema in STATE_SCHEMA.md",
            "description": "Create comprehensive documentation for state schema and migration system",
            "dependencies": [],
            "details": "Created docs/STATE_SCHEMA.md with:\n- Current version (1.0.0) documentation\n- WorkflowState interface with all fields\n- WorkflowStage enum values\n- Checkpoint interface\n- Stage-specific state schemas\n- Version history section\n- Migration system documentation\n- Adding new migrations guide\n- Migration rules and best practices\n- Troubleshooting section",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-05T02:31:30.888Z"
      },
      {
        "id": "19",
        "title": "Implement Secure YAML Parsing",
        "description": "Replace all instances of yaml.load() with safe parsing to prevent potential code execution risks.",
        "details": "1. Audit all YAML parsing locations in the codebase\n2. Replace unsafe yaml.load() calls with safe parsing:\n\n```typescript\n// Before\nconst data = yaml.load(content);\n\n// After\nconst data = yaml.load(content, { schema: yaml.JSON_SCHEMA });\n```\n\n3. Create a utility function for safe YAML parsing:\n\n```typescript\n// src/utils/yaml.ts\nimport yaml from 'js-yaml';\n\nexport function safeLoad(content: string): any {\n  return yaml.load(content, { schema: yaml.JSON_SCHEMA });\n}\n\nexport function safeDump(data: any): string {\n  return yaml.dump(data, { schema: yaml.JSON_SCHEMA });\n}\n```\n\n4. Replace all direct yaml.load calls with the safeLoad utility\n5. Add security tests to verify safe parsing\n6. Document the security improvement",
        "testStrategy": "1. Create unit tests with YAML content containing potentially executable code\n2. Verify that safe parsing prevents code execution\n3. Test with various YAML structures to ensure functionality is preserved\n4. Create security tests that attempt to exploit unsafe parsing\n5. Verify all YAML parsing locations use safe mode\n6. Test error handling for malformed YAML",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T05:50:28.712Z"
      },
      {
        "id": "20",
        "title": "Implement Performance Optimizations",
        "description": "Optimize performance by replacing sequential file operations with parallel processing and implementing other efficiency improvements.",
        "details": "1. Replace sequential await in loops with Promise.all():\n\n```typescript\n// Before\nfor (const file of files) {\n  const content = await fs.readFile(file, 'utf-8');\n  // process content\n}\n\n// After\nconst fileContents = await Promise.all(\n  files.map(file => fs.readFile(file, 'utf-8'))\n);\nfor (let i = 0; i < files.length; i++) {\n  const content = fileContents[i];\n  // process content\n}\n```\n\n2. Implement parallel file scanning:\n\n```typescript\nasync function scanDirectoryParallel(dir: string, pattern: string): Promise<string[]> {\n  const entries = await fs.readdir(dir, { withFileTypes: true });\n  \n  const results = await Promise.all(\n    entries.map(async (entry) => {\n      const fullPath = path.join(dir, entry.name);\n      \n      if (entry.isDirectory()) {\n        return scanDirectoryParallel(fullPath, pattern);\n      }\n      \n      if (entry.isFile() && minimatch(entry.name, pattern)) {\n        return [fullPath];\n      }\n      \n      return [];\n    })\n  );\n  \n  return results.flat();\n}\n```\n\n3. Add progress indicators for long operations:\n\n```typescript\nimport ora from 'ora';\n\nasync function processFilesWithProgress(files: string[]): Promise<Result[]> {\n  const spinner = ora('Processing files').start();\n  let processed = 0;\n  \n  const updateProgress = () => {\n    processed++;\n    spinner.text = `Processing files (${processed}/${files.length})`;\n  };\n  \n  try {\n    const results = await Promise.all(\n      files.map(async (file) => {\n        const result = await processFile(file);\n        updateProgress();\n        return result;\n      })\n    );\n    \n    spinner.succeed(`Processed ${files.length} files`);\n    return results;\n  } catch (error) {\n    spinner.fail(`Processing failed: ${error.message}`);\n    throw error;\n  }\n}\n```\n\n4. Optimize token estimation overhead by caching results\n5. Consider streaming YAML parsing for large files\n6. Implement batch processing for large repositories",
        "testStrategy": "1. Create performance benchmarks for key operations\n2. Compare performance before and after optimizations\n3. Test with repositories of various sizes (small, medium, large)\n4. Verify memory usage stays within target (<500MB)\n5. Test parallel file operations with different concurrency levels\n6. Ensure optimizations don't introduce race conditions or errors",
        "priority": "low",
        "dependencies": [
          "16",
          "17"
        ],
        "status": "done",
        "subtasks": [],
        "updatedAt": "2026-01-05T06:29:05.317Z"
      },
      {
        "id": "21",
        "title": "Design and Document pkf-core API Architecture",
        "description": "Design the public API for the new @pantheon-tech/pkf-core shared package, creating comprehensive TypeScript interface definitions, module export structure, versioning policy, and design documentation before code extraction begins.",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "## Overview\n\nThis task creates the architectural foundation for @pantheon-tech/pkf-core, the shared business logic package that will enable 60-65% code reuse between pkf-init and the planned pkf-mcp-server. **All deliverables have been completed.**\n\n## Completed Deliverables\n\n### 1. API Design Document (`docs/architecture/pkf-core-api.md`) \n\nCreated comprehensive documentation (1100+ lines) covering:\n\n- **Design Principles:** Framework-agnostic, stateless, composable, typed, error handling\n- **Module Architecture:** 7 modules with dependency graph:\n  - `type-mapper` - Document classification and directory mapping\n  - `schema` - Schema loading and validation\n  - `templates` - Template processing and rendering\n  - `frontmatter` - Frontmatter generation and parsing\n  - `scanner` - Document scanning and discovery\n  - `blueprint` - Blueprint parsing and summary extraction\n  - `utils` - Common utilities (YAML, file operations)\n- **Public API Reference:** Complete TypeScript function signatures for all modules\n- **Usage Examples:** 4 comprehensive examples showing real-world usage patterns\n- **Extension Points:** Custom type mappings, schema validation, template delimiters\n- **Design Decisions:** Documented alternatives considered and rationale\n\n### 2. Versioning Policy (`docs/architecture/pkf-core-versioning.md`)\n\nCreated comprehensive versioning document covering:\n\n- **Semantic Versioning:** MAJOR.MINOR.PATCH rules with examples\n- **API Stability Levels:** Stable, Beta, Experimental, Internal\n- **Deprecation Policy:** Minimum 2 minor versions support, JSDoc annotations, runtime warnings\n- **Breaking Change Guidelines:** Clear definitions and examples\n- **Compatibility Matrix:** pkf-init, pkf-mcp-server, and pkf-core versions\n- **Migration Support:** Codemods, parallel installation, feature flags\n- **LTS Policy:** 18 months active, 12 months maintenance\n\n### 3. TypeScript Interface Definitions (`packages/pkf-core/src/types/`)\n\nCreated 8 type definition files with full JSDoc documentation:\n\n- **`core.ts`** - PKFDocument, DocumentMetadata, PKFSchema, SchemaField, Result<T,E>, ValidationError, ValidationWarning\n- **`type-mapper.ts`** - DocumentType (10 types), TypeMappingOptions, ResolvedPath\n- **`schema.ts`** - SchemaLoaderOptions, ValidationResult, ISchemaLoader interface\n- **`templates.ts`** - TemplateVariables, TemplateProcessorOptions, ProcessedTemplate, ITemplateProcessor\n- **`frontmatter.ts`** - FrontmatterGeneratorOptions, GeneratedFrontmatter, ParsedFrontmatter\n- **`scanner.ts`** - ScannerOptions, ScanResult, ScanError, IDocumentScanner interface\n- **`blueprint.ts`** - ParsedBlueprint, AnalysisSummary, DocumentEntry, DirectoryStructure, MigrationPlan, MigrationPhase, Warning, BlueprintSummary\n- **`utils.ts`** - AtomicWriteOptions, SafeYamlOptions (supports json, core, failsafe schemas)\n- **`index.ts`** - Re-exports all types from all modules\n\n### 4. Package Configuration (`packages/pkf-core/package.json`)\n\nCreated ESM package configuration with:\n\n- **Subpath exports** for all 8 modules (main, type-mapper, schema, templates, frontmatter, scanner, blueprint, utils, types)\n- **Peer dependency** on js-yaml ^4.1.0\n- **Node.js >= 18.0.0** requirement\n- **TypeScript 5.3+** dev dependency\n- **Build scripts** for tsc, clean, typecheck\n\n### 5. TypeScript Configuration (`packages/pkf-core/tsconfig.json`)\n\nCreated strict TypeScript configuration:\n\n- **ES2022 target** with Node16 module resolution\n- **Strict mode** enabled with all strict checks\n- **Declaration files** and source maps enabled\n- **No unused locals/parameters** enforcement\n\n## Files Created\n\n1. `docs/architecture/pkf-core-api.md` - Main API design document\n2. `docs/architecture/pkf-core-versioning.md` - Versioning policy\n3. `packages/pkf-core/package.json` - Package configuration\n4. `packages/pkf-core/tsconfig.json` - TypeScript configuration\n5. `packages/pkf-core/README.md` - Package README\n6. `packages/pkf-core/src/types/core.ts` - Core shared types\n7. `packages/pkf-core/src/types/type-mapper.ts` - Type mapping interfaces\n8. `packages/pkf-core/src/types/schema.ts` - Schema interfaces\n9. `packages/pkf-core/src/types/templates.ts` - Template interfaces\n10. `packages/pkf-core/src/types/frontmatter.ts` - Frontmatter interfaces\n11. `packages/pkf-core/src/types/scanner.ts` - Scanner interfaces\n12. `packages/pkf-core/src/types/blueprint.ts` - Blueprint interfaces\n13. `packages/pkf-core/src/types/utils.ts` - Utility interfaces\n14. `packages/pkf-core/src/types/index.ts` - Type re-exports",
        "testStrategy": "## Verification Completed\n\n### 1. Documentation Review\n- [x] API design document is complete with all 7 modules documented\n- [x] Each module has clear purpose statement and example usage\n- [x] Design principles are clearly articulated\n- [x] Dependency relationships between modules are documented\n\n### 2. TypeScript Interface Validation\n- [x] Created `packages/pkf-core/` directory structure\n- [x] Added TypeScript configuration (`tsconfig.json`)\n- [x] TypeScript interfaces compile without errors\n- [x] No circular dependencies between type files (import pattern verified)\n\n### 3. Export Structure Validation\n- [x] package.json subpath exports follow Node.js ESM conventions\n- [x] All exports have both `types` and `import` conditions\n- [x] Package structure follows standard npm conventions\n\n### 4. Compatibility Check with Existing Code\n- [x] All relevant types from pkf-init have equivalent definitions\n- [x] Type mapping patterns from type-mapping.ts are preserved\n- [x] Blueprint summary patterns are accommodated with BlueprintSummary interface\n\n### 5. Peer Review Verification\n- [x] Design document reviewed for clarity and completeness\n- [x] Interface definitions designed for extensibility (generics, optional params)\n- [x] Versioning policy documented with practical deprecation timeline\n- [x] Alternative designs documented in Design Decisions section\n\n### 6. Future-Proofing Validation\n- [x] Interfaces support both pkf-init CLI and future pkf-mcp-server use cases\n- [x] Extension points exist for custom schema types (customMappings, customPatterns)\n- [x] No hardcoded paths or environment-specific assumptions\n\n### 7. Documentation Quality\n- [x] All public types have JSDoc comments\n- [x] Examples provided for complex interfaces in API design doc\n- [x] Edge cases documented (null handling via Result types, error conditions)",
        "subtasks": [
          {
            "id": 1,
            "title": "Create API Design Document",
            "description": "Create comprehensive API design documentation at docs/architecture/pkf-core-api.md covering design principles, module architecture, and public API reference",
            "dependencies": [],
            "details": "Created 1100+ line document covering all 7 modules (type-mapper, schema, templates, frontmatter, scanner, blueprint, utils), with dependency graph, complete TypeScript function signatures, usage examples, extension points, and design decisions with alternatives considered.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Create Versioning Policy Document",
            "description": "Create stability contract and versioning policy at docs/architecture/pkf-core-versioning.md with semantic versioning rules and deprecation policy",
            "dependencies": [],
            "details": "Created comprehensive versioning document with MAJOR.MINOR.PATCH rules, API stability levels (Stable, Beta, Experimental, Internal), deprecation policy with 2 minor version minimum support, compatibility matrix for pkf-init/pkf-mcp-server/pkf-core, and LTS policy.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Create TypeScript Interface Definitions",
            "description": "Create TypeScript interface definitions for all 7 modules in packages/pkf-core/src/types/ directory",
            "dependencies": [],
            "details": "Created 8 type definition files: core.ts (PKFDocument, Result<T,E>, ValidationError), type-mapper.ts (DocumentType, TypeMappingOptions), schema.ts (ISchemaLoader, ValidationResult), templates.ts (ITemplateProcessor, ProcessedTemplate), frontmatter.ts (ParsedFrontmatter, GeneratedFrontmatter), scanner.ts (IDocumentScanner, ScanResult), blueprint.ts (ParsedBlueprint, BlueprintSummary), utils.ts (AtomicWriteOptions, SafeYamlOptions), and index.ts re-exporting all types.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Create Package Configuration",
            "description": "Create package.json with ESM subpath exports for all modules and proper peer dependencies",
            "dependencies": [],
            "details": "Created package.json with subpath exports for all 8 modules (main, type-mapper, schema, templates, frontmatter, scanner, blueprint, utils, types), peer dependency on js-yaml ^4.1.0, Node.js >= 18.0.0 requirement, and build scripts.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Create TypeScript Configuration",
            "description": "Create tsconfig.json with strict mode and proper ESM configuration for the pkf-core package",
            "dependencies": [],
            "details": "Created strict TypeScript configuration with ES2022 target, Node16 module resolution, declaration files, source maps, and strict type checking enabled including noUnusedLocals, noUnusedParameters, and noImplicitReturns.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Validate TypeScript Compilation",
            "description": "Verify all TypeScript interfaces compile without errors and have no circular dependencies",
            "dependencies": [],
            "details": "Verified all type files compile correctly with proper import patterns. The scanner.ts imports from core.ts for PKFDocument reference, demonstrating the intended dependency structure without circular references.",
            "status": "done",
            "testStrategy": null,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2026-01-05T05:50:56.685Z"
      },
      {
        "id": "22",
        "title": "Create pkf-core Package Structure and Scaffolding",
        "description": "Set up the foundational package structure for @pantheon-tech/pkf-core, the shared business logic package that will enable 60-65% code reuse between pkf-init and the planned pkf-mcp-server.",
        "details": "## Overview\n\nThis task creates the package scaffolding for @pantheon-tech/pkf-core following the established patterns from pkf-init and pkf-validator packages. The structure must align with the API design from Task 21.\n\n## Deliverables\n\n### 1. Directory Structure\n\nCreate the following directory structure under `packages/pkf-core/`:\n\n```\npackages/pkf-core/\n├── src/\n│   ├── type-mapper/        # Document type mapping (from pkf-init/utils/type-mapping.ts)\n│   │   └── index.ts\n│   ├── schema/             # Schema loading and validation\n│   │   └── index.ts\n│   ├── templates/          # Template processing utilities\n│   │   └── index.ts\n│   ├── frontmatter/        # Frontmatter generation and parsing\n│   │   └── index.ts\n│   ├── scanner/            # Document scanning utilities\n│   │   └── index.ts\n│   ├── utils/              # Shared utilities (TokenEstimator, CostTracker candidates)\n│   │   └── index.ts\n│   ├── types/              # Shared type definitions\n│   │   └── index.ts\n│   └── index.ts            # Main entry point with public exports\n├── tests/\n│   ├── type-mapper/\n│   ├── schema/\n│   ├── templates/\n│   ├── frontmatter/\n│   ├── scanner/\n│   └── utils/\n├── package.json\n├── tsconfig.json\n├── vitest.config.ts\n└── README.md\n```\n\n### 2. Package Configuration (package.json)\n\nCreate `packages/pkf-core/package.json` following pkf-init pattern:\n\n```json\n{\n  \"name\": \"@pantheon-tech/pkf-core\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Core business logic for PKF - shared across pkf-init and pkf-mcp-server\",\n  \"type\": \"module\",\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\"\n    },\n    \"./type-mapper\": {\n      \"import\": \"./dist/type-mapper/index.js\",\n      \"types\": \"./dist/type-mapper/index.d.ts\"\n    },\n    \"./schema\": {\n      \"import\": \"./dist/schema/index.js\",\n      \"types\": \"./dist/schema/index.d.ts\"\n    },\n    \"./templates\": {\n      \"import\": \"./dist/templates/index.js\",\n      \"types\": \"./dist/templates/index.d.ts\"\n    },\n    \"./frontmatter\": {\n      \"import\": \"./dist/frontmatter/index.js\",\n      \"types\": \"./dist/frontmatter/index.d.ts\"\n    },\n    \"./scanner\": {\n      \"import\": \"./dist/scanner/index.js\",\n      \"types\": \"./dist/scanner/index.d.ts\"\n    },\n    \"./utils\": {\n      \"import\": \"./dist/utils/index.js\",\n      \"types\": \"./dist/utils/index.d.ts\"\n    },\n    \"./types\": {\n      \"import\": \"./dist/types/index.js\",\n      \"types\": \"./dist/types/index.d.ts\"\n    }\n  },\n  \"files\": [\"dist\", \"README.md\"],\n  \"publishConfig\": {\n    \"registry\": \"https://npm.pkg.github.com\",\n    \"access\": \"public\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/pantheon-tech/pkf.git\",\n    \"directory\": \"packages/pkf-core\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\",\n    \"test:coverage\": \"vitest run --coverage\",\n    \"lint\": \"eslint src\",\n    \"clean\": \"rm -rf dist\"\n  },\n  \"keywords\": [\"pkf\", \"documentation\", \"core\", \"shared\"],\n  \"author\": \"Pantheon Tech\",\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"js-yaml\": \"^4.1.0\"\n  },\n  \"devDependencies\": {\n    \"@types/js-yaml\": \"^4.0.9\",\n    \"@types/node\": \"^20.11.0\",\n    \"typescript\": \"^5.3.3\",\n    \"vitest\": \"^2.1.9\"\n  },\n  \"peerDependencies\": {},\n  \"engines\": {\n    \"node\": \">=20.0.0\"\n  }\n}\n```\n\n### 3. TypeScript Configuration (tsconfig.json)\n\nMatch pkf-init's configuration with ESM + NodeNext resolution:\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"NodeNext\",\n    \"moduleResolution\": \"NodeNext\",\n    \"lib\": [\"ES2022\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true,\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\", \"tests\"]\n}\n```\n\n### 4. Vitest Configuration (vitest.config.ts)\n\n```typescript\nimport { defineConfig } from 'vitest/config';\n\nexport default defineConfig({\n  test: {\n    globals: true,\n    environment: 'node',\n    include: ['tests/**/*.test.ts'],\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html'],\n      include: ['src/**/*.ts'],\n      thresholds: {\n        statements: 90,\n        branches: 85,\n        functions: 90,\n        lines: 90,\n      },\n    },\n    testTimeout: 10000,\n  },\n});\n```\n\n### 5. Initial Module Stubs\n\nCreate placeholder modules with JSDoc and type exports ready for implementation:\n\n**src/index.ts:**\n```typescript\n/**\n * @pantheon-tech/pkf-core\n * Core business logic for PKF - shared across pkf-init and pkf-mcp-server\n */\n\n// Re-export all modules\nexport * from './types/index.js';\nexport * from './type-mapper/index.js';\nexport * from './schema/index.js';\nexport * from './templates/index.js';\nexport * from './frontmatter/index.js';\nexport * from './scanner/index.js';\nexport * from './utils/index.js';\n```\n\n**src/types/index.ts:**\n```typescript\n/**\n * Core type definitions for PKF\n * These types are framework-agnostic and used across all PKF packages\n */\n\n// Placeholder - types will be extracted from pkf-init in subsequent task\nexport interface PKFDocument {\n  path: string;\n  type: string;\n  title?: string;\n}\n```\n\nEach module stub should include:\n- JSDoc module description\n- Placeholder exports that compile\n- TODO comments referencing the extraction task\n\n### 6. README.md\n\nCreate initial documentation:\n\n```markdown\n# @pantheon-tech/pkf-core\n\nCore business logic for the Project Knowledge Framework (PKF).\n\n## Overview\n\nThis package contains framework-agnostic utilities shared between:\n- `@pantheon-tech/pkf-init` - CLI initialization tool\n- `@pantheon-tech/pkf-mcp-server` - MCP server (planned)\n\n## Modules\n\n| Module | Description |\n|--------|-------------|\n| `type-mapper` | Document type to directory mapping |\n| `schema` | Schema loading and validation |\n| `templates` | Template processing utilities |\n| `frontmatter` | Frontmatter generation/parsing |\n| `scanner` | Document scanning utilities |\n| `utils` | Shared utilities |\n| `types` | TypeScript type definitions |\n\n## Installation\n\n```bash\nnpm install @pantheon-tech/pkf-core\n```\n\n## Usage\n\n```typescript\nimport { detectDocumentType, resolveTargetPath } from '@pantheon-tech/pkf-core/type-mapper';\nimport type { PKFDocument } from '@pantheon-tech/pkf-core/types';\n```\n\n## Development\n\n```bash\nnpm run build    # Compile TypeScript\nnpm run test     # Run tests\nnpm run lint     # Run linter\n```\n\n## License\n\nMIT\n```\n\n### 7. Integration with Monorepo\n\nEnsure package is properly integrated:\n- Added to `packages/` directory recognized by npm workspaces\n- Can be built with `npm run build:packages` from root\n- Can install dependencies with `npm install` from root\n\n## Implementation Notes\n\n- Follow the design principles from Task 21's API design document\n- All modules should be stateless with pure functions where possible\n- Maintain comprehensive TypeScript types\n- Use consistent error handling patterns\n- Keep dependencies minimal (only js-yaml initially)",
        "testStrategy": "## Verification Steps\n\n### 1. Package Structure Validation\n- [ ] Verify all directories exist under `packages/pkf-core/`\n- [ ] Confirm `src/` contains all 7 module directories plus `index.ts`\n- [ ] Confirm `tests/` mirrors `src/` module structure\n\n### 2. Configuration Validation\n- [ ] Run `npm install` from project root - should install pkf-core dependencies\n- [ ] Run `npm run build` from `packages/pkf-core/` - should compile successfully\n- [ ] Run `npm run build:packages` from root - pkf-core should build\n- [ ] Verify `dist/` directory is created with `.js`, `.d.ts`, and `.map` files\n\n### 3. TypeScript Configuration\n- [ ] All module stubs compile without errors\n- [ ] Declaration files (`.d.ts`) are generated\n- [ ] Source maps are generated\n- [ ] Module resolution works correctly (NodeNext)\n\n### 4. Exports Validation\n- [ ] Test main export: `import { PKFDocument } from '@pantheon-tech/pkf-core'`\n- [ ] Test subpath exports: `import { ... } from '@pantheon-tech/pkf-core/type-mapper'`\n- [ ] Verify TypeScript recognizes all type exports\n\n### 5. Test Infrastructure\n- [ ] Run `npm run test` from `packages/pkf-core/` - should execute (may have no tests initially)\n- [ ] Run `npm run test:coverage` - coverage report should be generated\n- [ ] Vitest configuration is recognized\n\n### 6. Integration Tests\n```typescript\n// Create test file: tests/setup.test.ts\nimport { describe, it, expect } from 'vitest';\n\ndescribe('pkf-core package structure', () => {\n  it('exports from main entry point', async () => {\n    const core = await import('../src/index.js');\n    expect(core).toBeDefined();\n  });\n\n  it('exports from type-mapper subpath', async () => {\n    const typeMapper = await import('../src/type-mapper/index.js');\n    expect(typeMapper).toBeDefined();\n  });\n\n  // Repeat for all module subpaths\n});\n```\n\n### 7. Monorepo Integration\n- [ ] Package appears in `npm ls` output from root\n- [ ] Other packages can depend on it: add `\"@pantheon-tech/pkf-core\": \"workspace:*\"` to pkf-init\n- [ ] Cross-package TypeScript references work\n\n### 8. Documentation\n- [ ] README.md exists and is readable\n- [ ] Module descriptions match intended functionality\n- [ ] Installation and usage examples are accurate",
        "status": "done",
        "dependencies": [
          "21"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-05T06:03:46.637Z"
      },
      {
        "id": "23",
        "title": "Extract Type-Mapper Module to pkf-core Package",
        "description": "Extract the type-mapping module from pkf-init to the new pkf-core shared package, enabling 100% code reuse for document type to schema mapping logic across pkf-init and future pkf-mcp-server.",
        "details": "## Overview\n\nThis task extracts the type-mapper module from `packages/pkf-init/src/utils/type-mapping.ts` to `packages/pkf-core/src/type-mapper/`, making it the first code extraction to the shared pkf-core package. The module contains ~490 lines of framework-agnostic logic for document type detection, path resolution, and schema mapping.\n\n## Prerequisites\n\n- Task 22 (pkf-core scaffolding) must be complete with directory structure and package configuration in place\n\n## Implementation Steps\n\n### 1. Create Type-Mapper Module in pkf-core\n\nCopy and adapt the source file:\n\n```typescript\n// packages/pkf-core/src/type-mapper/index.ts\n\n// Copy contents from packages/pkf-init/src/utils/type-mapping.ts\n// Adjust imports - this module only uses Node's 'path' module\nimport * as path from 'path';\n\n// All exports remain the same:\n// - PKF_TYPE_TO_DIRECTORY (constant)\n// - DOC_TYPE_TO_SCHEMA (constant)\n// - ROOT_LEVEL_FILES (Set)\n// - PACKAGE_ROOT_FILES (Set)\n// - detectDocumentType(filePath: string, content?: string): string\n// - resolveTargetPath(sourcePath, docType, rootDir, docsDir): string\n// - getRequiredDirectories(docTypes: Set<string>): string[]\n// - shouldExcludeFromReorganization(filePath: string): boolean\n// - normalizeDocType(docType: string): string\n// - getSchemaForDocType(docType: string): string\n// - default export object with all functions/constants\n```\n\n### 2. Extract Related Types to pkf-core/types\n\nCreate shared types if the type-mapper introduces any (currently uses only primitives):\n\n```typescript\n// packages/pkf-core/src/types/type-mapper.ts\nexport type DocumentType = string; // Could expand to union type in future\nexport type SchemaName = 'base-doc' | 'guide' | 'spec' | 'adr' | 'proposal' | 'register';\n\n// packages/pkf-core/src/types/index.ts\nexport * from './type-mapper.js';\n```\n\n### 3. Configure pkf-core Package Exports\n\nUpdate `packages/pkf-core/package.json` exports:\n\n```json\n{\n  \"exports\": {\n    \".\": {\n      \"import\": \"./dist/index.js\",\n      \"types\": \"./dist/index.d.ts\"\n    },\n    \"./type-mapper\": {\n      \"import\": \"./dist/type-mapper/index.js\",\n      \"types\": \"./dist/type-mapper/index.d.ts\"\n    }\n  }\n}\n```\n\n### 4. Write Comprehensive Unit Tests\n\nCreate test file at `packages/pkf-core/tests/type-mapper/index.test.ts`:\n\n```typescript\nimport { describe, it, expect } from 'vitest';\nimport {\n  PKF_TYPE_TO_DIRECTORY,\n  DOC_TYPE_TO_SCHEMA,\n  detectDocumentType,\n  resolveTargetPath,\n  getRequiredDirectories,\n  shouldExcludeFromReorganization,\n  normalizeDocType,\n  getSchemaForDocType,\n  ROOT_LEVEL_FILES,\n  PACKAGE_ROOT_FILES,\n} from '@pantheon-tech/pkf-core/type-mapper';\n\ndescribe('type-mapper', () => {\n  describe('PKF_TYPE_TO_DIRECTORY', () => {\n    it('should map readme to root', () => {\n      expect(PKF_TYPE_TO_DIRECTORY['readme']).toBe('');\n    });\n    it('should map guides to docs/guides', () => {\n      expect(PKF_TYPE_TO_DIRECTORY['guide']).toBe('docs/guides');\n    });\n    // Test all ~45 type mappings\n  });\n\n  describe('detectDocumentType', () => {\n    it('should detect README files', () => {\n      expect(detectDocumentType('README.md')).toBe('readme');\n      expect(detectDocumentType('/project/README.md')).toBe('readme');\n    });\n    it('should detect ADR files by path pattern', () => {\n      expect(detectDocumentType('docs/adr/ADR-001.md')).toBe('adr');\n    });\n    it('should detect types from content when path is generic', () => {\n      const content = '## API Reference\\n### Endpoints';\n      expect(detectDocumentType('doc.md', content)).toBe('api-reference');\n    });\n    // Test all 25+ detection patterns\n  });\n\n  describe('resolveTargetPath', () => {\n    it('should keep root files at root', () => {\n      expect(resolveTargetPath('README.md', 'readme', '/project', 'docs')).toBe('README.md');\n    });\n    it('should resolve guide to docs/guides', () => {\n      expect(resolveTargetPath('guide.md', 'guide', '/project', 'docs')).toBe('docs/guides/guide.md');\n    });\n    it('should handle monorepo package paths', () => {\n      expect(resolveTargetPath('packages/foo/README.md', 'readme', '/project', 'docs')).toBe('packages/foo/README.md');\n    });\n  });\n\n  describe('normalizeDocType', () => {\n    it('should normalize aliases', () => {\n      expect(normalizeDocType('user-guide')).toBe('guide-user');\n      expect(normalizeDocType('api-docs')).toBe('api-reference');\n    });\n    it('should convert spaces and underscores to hyphens', () => {\n      expect(normalizeDocType('user_guide')).toBe('guide-user');\n    });\n  });\n\n  describe('getSchemaForDocType', () => {\n    it('should return correct schema for known types', () => {\n      expect(getSchemaForDocType('adr')).toBe('adr');\n      expect(getSchemaForDocType('guide')).toBe('guide');\n    });\n    it('should fallback to base-doc for unknown types', () => {\n      expect(getSchemaForDocType('unknown-type')).toBe('base-doc');\n    });\n  });\n\n  describe('shouldExcludeFromReorganization', () => {\n    it('should exclude node_modules', () => {\n      expect(shouldExcludeFromReorganization('node_modules/pkg/README.md')).toBe(true);\n    });\n    it('should exclude .git', () => {\n      expect(shouldExcludeFromReorganization('.git/hooks/pre-commit')).toBe(true);\n    });\n    it('should not exclude regular docs', () => {\n      expect(shouldExcludeFromReorganization('docs/guide.md')).toBe(false);\n    });\n  });\n});\n```\n\nTarget: 90%+ test coverage across all exported functions and constants.\n\n### 5. Update pkf-init to Import from pkf-core\n\nModify `packages/pkf-init/package.json`:\n\n```json\n{\n  \"dependencies\": {\n    \"@pantheon-tech/pkf-core\": \"workspace:*\"\n  }\n}\n```\n\nUpdate import in `packages/pkf-init/src/migration/worker.ts`:\n\n```typescript\n// Before:\nimport { getSchemaForDocType } from '../utils/type-mapping.js';\n\n// After:\nimport { getSchemaForDocType } from '@pantheon-tech/pkf-core/type-mapper';\n```\n\nCreate a re-export in pkf-init for backward compatibility (optional):\n\n```typescript\n// packages/pkf-init/src/utils/type-mapping.ts\n// Re-export everything from pkf-core for backward compatibility\nexport * from '@pantheon-tech/pkf-core/type-mapper';\n```\n\n### 6. Add JSDoc Documentation\n\nEnsure all exports have comprehensive JSDoc:\n\n```typescript\n/**\n * Detect document type from file path and optional content.\n * \n * Uses pattern matching on file paths and content analysis to determine\n * the PKF document type (readme, guide, api-reference, adr, etc.).\n * \n * @param filePath - Path to the file (relative or absolute)\n * @param content - Optional file content for content-based type detection\n * @returns Detected document type (defaults to 'generic' if unrecognized)\n * \n * @example\n * ```typescript\n * detectDocumentType('README.md') // returns 'readme'\n * detectDocumentType('docs/adr/ADR-001.md') // returns 'adr'\n * detectDocumentType('doc.md', '## API\\n### Endpoints') // returns 'api-reference'\n * ```\n */\nexport function detectDocumentType(filePath: string, content?: string): string {\n  // ...\n}\n```\n\n### 7. Build and Verify\n\n```bash\n# Build pkf-core\ncd packages/pkf-core && npm run build\n\n# Run pkf-core tests\nnpm test\n\n# Build pkf-init with new dependency\ncd ../pkf-init && npm install && npm run build\n\n# Run pkf-init tests to verify no regressions\nnpm test\n```\n\n## Key Files\n\n| File | Action |\n|------|--------|\n| `packages/pkf-core/src/type-mapper/index.ts` | Create (copy from pkf-init) |\n| `packages/pkf-core/src/types/type-mapper.ts` | Create (optional type exports) |\n| `packages/pkf-core/package.json` | Update exports |\n| `packages/pkf-core/tests/type-mapper/index.test.ts` | Create tests |\n| `packages/pkf-init/package.json` | Add pkf-core dependency |\n| `packages/pkf-init/src/migration/worker.ts` | Update import |\n| `packages/pkf-init/src/utils/type-mapping.ts` | Convert to re-export |\n\n## Key Exports from Type-Mapper\n\n| Export | Type | Description |\n|--------|------|-------------|\n| `PKF_TYPE_TO_DIRECTORY` | `Record<string, string>` | Maps ~45 document types to target directories |\n| `DOC_TYPE_TO_SCHEMA` | `Record<string, string>` | Maps document types to schema names |\n| `ROOT_LEVEL_FILES` | `Set<string>` | Files that should stay at project root |\n| `PACKAGE_ROOT_FILES` | `Set<string>` | Files that should stay at package root |\n| `detectDocumentType()` | `function` | Detect doc type from path/content |\n| `resolveTargetPath()` | `function` | Resolve PKF-compliant target path |\n| `getRequiredDirectories()` | `function` | Get dirs needed for doc types |\n| `shouldExcludeFromReorganization()` | `function` | Check if path should be excluded |\n| `normalizeDocType()` | `function` | Normalize doc type aliases |\n| `getSchemaForDocType()` | `function` | Get schema for document type |\n\n## Notes\n\n- The type-mapping module has no external dependencies beyond Node's `path` module, making it an ideal first extraction\n- Only one file in pkf-init imports from type-mapping (`migration/worker.ts`), minimizing update scope\n- The module is ~490 lines with comprehensive type-to-directory and type-to-schema mappings",
        "testStrategy": "## Verification Strategy\n\n### 1. Unit Test Coverage (pkf-core)\n- [ ] Run `npm test -- --coverage` in pkf-core and verify 90%+ coverage for type-mapper module\n- [ ] Verify all 10 exports are tested:\n  - `PKF_TYPE_TO_DIRECTORY` constant (45+ mappings)\n  - `DOC_TYPE_TO_SCHEMA` constant (45+ mappings)\n  - `ROOT_LEVEL_FILES` Set (9 entries)\n  - `PACKAGE_ROOT_FILES` Set (3 entries)\n  - `detectDocumentType()` function (25+ patterns)\n  - `resolveTargetPath()` function (root, package, nested paths)\n  - `getRequiredDirectories()` function\n  - `shouldExcludeFromReorganization()` function (12+ patterns)\n  - `normalizeDocType()` function (alias resolution)\n  - `getSchemaForDocType()` function (fallback behavior)\n\n### 2. Integration Tests (pkf-init)\n- [ ] Run full pkf-init test suite: `cd packages/pkf-init && npm test`\n- [ ] Verify all 218+ existing tests pass\n- [ ] Pay special attention to migration worker tests that use type-mapping\n\n### 3. Build Verification\n- [ ] `cd packages/pkf-core && npm run build` succeeds\n- [ ] Generated `.d.ts` files include all exports\n- [ ] `cd packages/pkf-init && npm run build` succeeds with new import\n\n### 4. Import Path Verification\n- [ ] Verify subpath import works: `import { getSchemaForDocType } from '@pantheon-tech/pkf-core/type-mapper'`\n- [ ] Verify main export works: `import { detectDocumentType } from '@pantheon-tech/pkf-core'`\n- [ ] Verify TypeScript types are correctly exported\n\n### 5. Regression Testing\n- [ ] Create a test file that uses all type-mapper exports\n- [ ] Compare outputs with original pkf-init implementation for edge cases:\n  - Paths with backslashes (Windows)\n  - Paths with special characters\n  - Content with various markdown patterns\n  - Unknown/generic document types\n\n### 6. Documentation Verification\n- [ ] All exported functions have JSDoc comments\n- [ ] JSDoc includes @param, @returns, and @example tags\n- [ ] Type exports are documented\n\n### 7. Package Structure Verification\n- [ ] `packages/pkf-core/dist/type-mapper/index.js` exists\n- [ ] `packages/pkf-core/dist/type-mapper/index.d.ts` exists\n- [ ] Package exports work from consuming packages",
        "status": "done",
        "dependencies": [
          "22"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-05T06:15:14.447Z"
      },
      {
        "id": "24",
        "title": "Extract Schema Utilities to pkf-core Package",
        "description": "Extract schema loading, parsing, and validation utilities from pkf-init to the pkf-core shared package, enabling 80% code reuse for schema operations across pkf-init and future pkf-mcp-server.",
        "details": "## Overview\n\nThis task extracts schema-related utilities from `packages/pkf-init/src/` to `packages/pkf-core/src/schema/`, creating a unified schema handling module that can be shared across packages. The extraction complements the type-mapper module (Task 23) and provides the foundation for consistent schema operations.\n\n## Current Implementation Analysis\n\nSchema-related code is scattered across pkf-init:\n- **`stages/schema-design.ts`**: Contains `validateSchemasYaml()` (~125 lines) for YAML schema validation, `looksLikeSchemasYaml()` for structure detection, and `extractSchemasYaml()` for parsing agent output\n- **`generators/structure.ts`**: Uses `yaml.load()` for schema parsing at line 60, extracts document types from schemas\n- **`generators/config.ts`**: Uses `yaml.load()` at line 80 for schema parsing, builds document type configurations\n\nRelated code in pkf-validator (reference, not extraction target):\n- **`utils/schema-utils.ts`**: AJV-based JSON Schema validation with `compileSchema()`, `validateWithSchema()`, and format handlers\n- **`parsers/schema-dsl-parser.ts`**: Full Schema DSL parser with inheritance resolution and JSON Schema conversion\n\n## Implementation Steps\n\n### Step 1: Create Schema Module Structure in pkf-core\n\nCreate the following files under `packages/pkf-core/src/schema/`:\n\n```\npackages/pkf-core/src/schema/\n├── index.ts           # Public API exports\n├── loader.ts          # SchemaLoader class for loading schema files\n├── validator.ts       # Schema validation utilities\n└── types.ts           # Schema-related type definitions\n```\n\n### Step 2: Define Schema Types (`types.ts`)\n\n```typescript\n/**\n * Parsed PKF Schema DSL structure\n */\nexport interface SchemasYaml {\n  version: string;\n  schemas: Record<string, SchemaDefinition>;\n}\n\n/**\n * A single schema definition from schemas.yaml\n */\nexport interface SchemaDefinition {\n  _extends?: string;\n  _description?: string;\n  properties?: Record<string, PropertyDefinition>;\n}\n\n/**\n * Property definition within a schema\n */\nexport interface PropertyDefinition {\n  type: 'string' | 'number' | 'boolean' | 'date' | 'array' | 'object';\n  required?: boolean;\n  description?: string;\n  default?: unknown;\n  enum?: unknown[];\n  pattern?: string;\n  items?: { type: string; enum?: unknown[] };\n}\n\n/**\n * Result of schema validation\n */\nexport interface SchemaValidationResult {\n  valid: boolean;\n  errors: string[];\n  warnings: string[];\n}\n\n/**\n * Schema loading options\n */\nexport interface SchemaLoadOptions {\n  /** Whether to validate after loading */\n  validate?: boolean;\n  /** Whether to resolve inheritance */\n  resolveInheritance?: boolean;\n}\n```\n\n### Step 3: Implement SchemaLoader Class (`loader.ts`)\n\nExtract and enhance schema loading logic from pkf-init:\n\n```typescript\nimport * as yaml from 'js-yaml';\nimport type { SchemasYaml, SchemaLoadOptions } from './types.js';\n\n/**\n * SchemaLoader - Load and parse PKF schema files\n */\nexport class SchemaLoader {\n  /**\n   * Load schemas from YAML string\n   */\n  load(yamlContent: string, options?: SchemaLoadOptions): SchemasYaml | null {\n    // Parse YAML safely\n    const parsed = yaml.load(yamlContent, { schema: yaml.JSON_SCHEMA });\n    // Validate structure\n    // Optionally resolve inheritance\n    // Return typed result\n  }\n\n  /**\n   * Load schemas from file path\n   */\n  async loadFile(filePath: string, options?: SchemaLoadOptions): Promise<SchemasYaml | null> {\n    // Read file\n    // Call load()\n  }\n\n  /**\n   * Check if content looks like valid schemas.yaml\n   */\n  looksLikeSchemasYaml(content: string): boolean {\n    // Extract from schema-design.ts lines 619-625\n    const hasVersion = /^version:\\s*[\"']?\\d+\\.\\d+/m.test(content);\n    const hasSchemas = /^schemas:\\s*$/m.test(content) || /^schemas:\\s*\\n/m.test(content);\n    return hasVersion && hasSchemas;\n  }\n\n  /**\n   * Extract schema names from parsed schemas\n   */\n  getSchemaNames(schemas: SchemasYaml): string[] {\n    return Object.keys(schemas.schemas || {});\n  }\n}\n```\n\n### Step 4: Implement Schema Validator (`validator.ts`)\n\nExtract validation logic from `schema-design.ts` (lines 633-757):\n\n```typescript\nimport type { SchemasYaml, SchemaValidationResult } from './types.js';\n\n/**\n * Validate schemas.yaml structure\n */\nexport function validateSchemasYaml(schemas: SchemasYaml): SchemaValidationResult {\n  const errors: string[] = [];\n  const warnings: string[] = [];\n\n  // Validate version format\n  if (!schemas.version || !/^\\d+\\.\\d+$/.test(String(schemas.version))) {\n    errors.push('Invalid or missing version field');\n  }\n\n  // Validate schemas object exists\n  if (!schemas.schemas || typeof schemas.schemas !== 'object') {\n    errors.push('Missing or invalid schemas object');\n  } else {\n    // Validate each schema definition\n    for (const [name, schema] of Object.entries(schemas.schemas)) {\n      // Validate schema name format (lowercase alphanumeric with hyphens)\n      if (!/^[a-z][a-z0-9-]*$/.test(name)) {\n        errors.push(`Invalid schema name: ${name}`);\n      }\n      // Validate _extends references\n      if (schema._extends && !schemas.schemas[schema._extends]) {\n        errors.push(`Schema \"${name}\" extends unknown schema \"${schema._extends}\"`);\n      }\n      // Validate properties\n      if (schema.properties) {\n        for (const [propName, propDef] of Object.entries(schema.properties)) {\n          if (!propDef.type) {\n            errors.push(`Property \"${propName}\" in schema \"${name}\" missing type`);\n          }\n        }\n      }\n    }\n  }\n\n  return { valid: errors.length === 0, errors, warnings };\n}\n\n/**\n * Validate data against a schema definition (lightweight validation)\n */\nexport function validateAgainstSchema(\n  data: Record<string, unknown>,\n  schema: SchemaDefinition\n): SchemaValidationResult {\n  // Check required fields\n  // Validate types\n  // Check enum values\n}\n```\n\n### Step 5: Create Public API (`index.ts`)\n\n```typescript\n// Types\nexport type {\n  SchemasYaml,\n  SchemaDefinition,\n  PropertyDefinition,\n  SchemaValidationResult,\n  SchemaLoadOptions,\n} from './types.js';\n\n// Classes\nexport { SchemaLoader } from './loader.js';\n\n// Functions\nexport { validateSchemasYaml, validateAgainstSchema } from './validator.js';\n\n// Convenience function\nexport function loadSchema(yamlContent: string): SchemasYaml | null {\n  const loader = new SchemaLoader();\n  return loader.load(yamlContent, { validate: true });\n}\n```\n\n### Step 6: Update Package Exports in pkf-core\n\nAdd to `packages/pkf-core/package.json` exports:\n\n```json\n{\n  \"exports\": {\n    \".\": { \"import\": \"./dist/index.js\", \"types\": \"./dist/index.d.ts\" },\n    \"./type-mapper\": { \"import\": \"./dist/type-mapper/index.js\", \"types\": \"./dist/type-mapper/index.d.ts\" },\n    \"./schema\": { \"import\": \"./dist/schema/index.js\", \"types\": \"./dist/schema/index.d.ts\" }\n  }\n}\n```\n\n### Step 7: Update pkf-init Imports\n\nUpdate the following files to use pkf-core:\n\n**`src/stages/schema-design.ts`**:\n```typescript\n// Before\nimport * as jsYaml from 'js-yaml';\n\n// After\nimport { SchemaLoader, validateSchemasYaml } from '@pantheon-tech/pkf-core/schema';\n\n// Replace validateSchemasYaml method with:\nprivate async validateSchemasYaml(yaml: string): Promise<ValidationResult> {\n  const loader = new SchemaLoader();\n  const schemas = loader.load(yaml);\n  if (!schemas) {\n    return { valid: false, errors: ['Failed to parse YAML'], warnings: [] };\n  }\n  return validateSchemasYaml(schemas);\n}\n```\n\n**`src/generators/structure.ts`**:\n```typescript\n// Before\nimport * as yaml from 'js-yaml';\n// Line 60: const schemas = yaml.load(schemasYaml) as Record<string, unknown>;\n\n// After\nimport { SchemaLoader } from '@pantheon-tech/pkf-core/schema';\n// const loader = new SchemaLoader();\n// const schemas = loader.load(schemasYaml);\n```\n\n**`src/generators/config.ts`**:\n```typescript\n// Before\nimport * as yaml from 'js-yaml';\n// Line 80: const schemas = yaml.load(schemasYaml) as Record<string, unknown>;\n\n// After\nimport { SchemaLoader } from '@pantheon-tech/pkf-core/schema';\n```\n\n### Step 8: Write Comprehensive Unit Tests\n\nCreate `packages/pkf-core/tests/schema/`:\n\n```typescript\n// loader.test.ts\ndescribe('SchemaLoader', () => {\n  describe('load()', () => {\n    it('should parse valid schemas.yaml content');\n    it('should return null for invalid YAML');\n    it('should handle empty schemas object');\n    it('should preserve all schema properties');\n  });\n\n  describe('looksLikeSchemasYaml()', () => {\n    it('should detect valid schemas.yaml structure');\n    it('should reject content without version');\n    it('should reject content without schemas key');\n  });\n});\n\n// validator.test.ts\ndescribe('validateSchemasYaml', () => {\n  it('should validate correct schema structure');\n  it('should error on invalid version format');\n  it('should error on invalid schema name');\n  it('should error on unknown _extends reference');\n  it('should error on missing property type');\n  it('should warn on empty properties');\n});\n\ndescribe('validateAgainstSchema', () => {\n  it('should validate data matches schema');\n  it('should detect missing required fields');\n  it('should validate enum values');\n});\n```\n\n## Key Exports\n\n| Export | Type | Purpose |\n|--------|------|---------|\n| `SchemaLoader` | class | Load and parse schema files |\n| `loadSchema()` | function | Convenience function for loading schemas |\n| `validateSchemasYaml()` | function | Validate schemas.yaml structure |\n| `validateAgainstSchema()` | function | Validate data against schema definition |\n| `SchemasYaml` | type | Parsed schemas.yaml structure |\n| `SchemaDefinition` | type | Individual schema definition |\n| `SchemaValidationResult` | type | Validation result with errors/warnings |\n\n## Notes\n\n- The pkf-validator package has more comprehensive schema utilities using AJV. This extraction focuses on the lightweight schema loading and validation needed for pkf-init and pkf-mcp-server.\n- For full JSON Schema validation, consumers should use pkf-validator's `validateWithSchema()`.\n- The SchemaLoader uses safe YAML parsing per Task 19 (secure YAML parsing).",
        "testStrategy": "## Verification Strategy\n\n### 1. Unit Test Coverage (pkf-core)\n- [ ] Run `npm test -- --coverage` in pkf-core and verify 90%+ coverage for schema module\n- [ ] Verify all public exports are tested:\n  - `SchemaLoader` class: `load()`, `loadFile()`, `looksLikeSchemasYaml()`, `getSchemaNames()`\n  - `loadSchema()` convenience function\n  - `validateSchemasYaml()` function\n  - `validateAgainstSchema()` function\n- [ ] Test edge cases: empty schemas, malformed YAML, circular inheritance, invalid property types\n\n### 2. Integration Testing with pkf-init\n- [ ] Run `npm test` in pkf-init and verify all 218+ existing tests pass\n- [ ] Verify schema-design stage works correctly with extracted utilities\n- [ ] Test structure generator produces correct directory structure\n- [ ] Test config generator produces valid pkf.config.yaml\n\n### 3. Build Verification\n- [ ] Run `npm run build` in pkf-core - verify no TypeScript errors\n- [ ] Run `npm run build` in pkf-init - verify no TypeScript errors\n- [ ] Verify pkf-core exports are accessible from pkf-init:\n  ```typescript\n  import { SchemaLoader, validateSchemasYaml } from '@pantheon-tech/pkf-core/schema';\n  ```\n\n### 4. Type Safety Verification\n- [ ] Verify all exported types are correctly inferred in pkf-init\n- [ ] Check that `SchemasYaml` type matches actual schema file structure\n- [ ] Verify `SchemaValidationResult` is compatible with existing ValidationResult interfaces\n\n### 5. Schema Validation Testing\n- [ ] Test with valid PKF base schema (from schema-design.ts PKF_BASE_SCHEMA)\n- [ ] Test validation catches:\n  - Missing version field\n  - Invalid version format (must be X.Y)\n  - Invalid schema names (must be lowercase alphanumeric with hyphens)\n  - Unknown _extends references\n  - Missing property types\n  - Invalid property types\n\n### 6. Compatibility with pkf-validator\n- [ ] Verify schemas loaded by SchemaLoader can be passed to pkf-validator's SchemaDSLParser\n- [ ] Confirm no conflicts between schema module types and pkf-validator types\n\n### 7. Documentation Verification\n- [ ] JSDoc comments on all public exports\n- [ ] README.md in pkf-core documents schema module usage\n- [ ] Example usage code compiles and runs correctly",
        "status": "done",
        "dependencies": [
          "23"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-05T06:38:23.218Z"
      },
      {
        "id": "25",
        "title": "Extract Template Processing Module to pkf-core Package",
        "description": "Extract template loading, variable substitution, and processing utilities from pkf-init to the pkf-core shared package, enabling 60% code reuse for template operations across pkf-init and future pkf-mcp-server.",
        "details": "## Overview\n\nThis task extracts template processing functionality from scattered locations in `packages/pkf-init/` to a unified `packages/pkf-core/src/templates/` module. The extraction builds on the schema utilities (Task 24) and consolidates template handling from migration worker (lines 659-696), registers generator, and establishes integration with the existing PKF templates directory.\n\n## Current Template Implementation Analysis\n\nTemplate-related code exists in multiple pkf-init locations:\n- **`migration/worker.ts`** (lines 659-696): `generateInitialContent()` method with hardcoded templates for 14 document types (readme, guide, adr, spec, changelog, todo, issues, api-reference, architecture, etc.)\n- **`generators/registers.ts`**: `RegisterInitializer` class with `createTodo()`, `createIssues()`, `createChangelog()` methods containing template strings\n- **`generators/config.ts`** (lines 36, 52, 136): References to `templates` path in config generation\n\nExternal template files at `/templates/`:\n- 13 `.template.md` files using `{{PLACEHOLDER}}` syntax\n- README.template.md, CLAUDE.template.md, ADR.template.md, etc.\n\n## Implementation Steps\n\n### Step 1: Create Templates Module Structure in pkf-core\n\n```\npackages/pkf-core/src/templates/\n├── index.ts           # Public API exports\n├── manager.ts         # TemplateManager class\n├── processor.ts       # Template processing functions\n└── types.ts           # Template-related type definitions\n```\n\n### Step 2: Define Template Types (`types.ts`)\n\n```typescript\n/**\n * Template variable values for substitution\n */\nexport interface TemplateVariables {\n  [key: string]: string | number | boolean | undefined;\n}\n\n/**\n * Options for template processing\n */\nexport interface TemplateProcessorOptions {\n  /** Directory containing template files */\n  templateDir?: string;\n  /** Custom template directory to override defaults */\n  customTemplateDir?: string;\n  /** Placeholder delimiters, defaults to ['{{', '}}'] */\n  delimiters?: [string, string];\n  /** Throw error on missing variables vs leaving placeholder */\n  strict?: boolean;\n  /** Default values for common variables */\n  defaults?: TemplateVariables;\n}\n\n/**\n * Result of template processing\n */\nexport interface ProcessedTemplate {\n  /** Processed content with variables substituted */\n  content: string;\n  /** Variables that were successfully substituted */\n  usedVariables: string[];\n  /** Variables found in template but not provided */\n  missingVariables: string[];\n  /** Source template path (if loaded from file) */\n  sourcePath?: string;\n}\n\n/**\n * Template metadata extracted from file\n */\nexport interface TemplateInfo {\n  /** Template name (filename without extension) */\n  name: string;\n  /** Full path to template file */\n  path: string;\n  /** Variables found in the template */\n  variables: string[];\n  /** Document type this template is for (if detectable) */\n  docType?: string;\n}\n\n/**\n * Built-in template names matching document types\n */\nexport type BuiltInTemplateName = \n  | 'readme' | 'guide' | 'guide-user' | 'guide-developer'\n  | 'adr' | 'spec' | 'specification' | 'proposal'\n  | 'changelog' | 'todo' | 'issues'\n  | 'api' | 'api-reference' | 'architecture' | 'design-doc'\n  | 'claude' | 'contributing';\n```\n\n### Step 3: Implement TemplateManager Class (`manager.ts`)\n\n```typescript\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport type { TemplateProcessorOptions, TemplateInfo, TemplateVariables, ProcessedTemplate } from './types.js';\nimport { processTemplate, extractVariables } from './processor.js';\n\n/**\n * TemplateManager - Load and process PKF templates\n * \n * Supports loading templates from:\n * 1. Custom template directory (highest priority)\n * 2. Project's templates/ directory\n * 3. Built-in templates bundled with pkf-core\n */\nexport class TemplateManager {\n  private templateDir: string;\n  private customTemplateDir: string | null;\n  private templateCache: Map<string, string> = new Map();\n  private options: TemplateProcessorOptions;\n\n  constructor(options?: TemplateProcessorOptions) {\n    this.options = options ?? {};\n    this.templateDir = options?.templateDir ?? path.join(__dirname, '../../templates');\n    this.customTemplateDir = options?.customTemplateDir ?? null;\n  }\n\n  /**\n   * Load a template by name\n   * @param templateName - Template name (without .template.md extension)\n   * @returns Raw template content\n   */\n  async loadTemplate(templateName: string): Promise<string> {\n    // Check cache first\n    if (this.templateCache.has(templateName)) {\n      return this.templateCache.get(templateName)!;\n    }\n\n    // Try custom directory first\n    if (this.customTemplateDir) {\n      try {\n        const customPath = this.resolveTemplatePath(this.customTemplateDir, templateName);\n        const content = await fs.readFile(customPath, 'utf-8');\n        this.templateCache.set(templateName, content);\n        return content;\n      } catch {\n        // Fall through to default templates\n      }\n    }\n\n    // Load from default template directory\n    const defaultPath = this.resolveTemplatePath(this.templateDir, templateName);\n    const content = await fs.readFile(defaultPath, 'utf-8');\n    this.templateCache.set(templateName, content);\n    return content;\n  }\n\n  /**\n   * Process a template with variable substitution\n   */\n  async process(\n    templateName: string,\n    variables: TemplateVariables\n  ): Promise<ProcessedTemplate> {\n    const template = await this.loadTemplate(templateName);\n    return processTemplate(template, variables, this.options);\n  }\n\n  /**\n   * Get list of available templates\n   */\n  async getAvailableTemplates(): Promise<TemplateInfo[]> {\n    const templates: TemplateInfo[] = [];\n    \n    const scanDir = async (dir: string) => {\n      try {\n        const files = await fs.readdir(dir);\n        for (const file of files) {\n          if (file.endsWith('.template.md') || file.endsWith('.md')) {\n            const fullPath = path.join(dir, file);\n            const content = await fs.readFile(fullPath, 'utf-8');\n            const name = file.replace(/\\.template\\.md$/, '').replace(/\\.md$/, '');\n            templates.push({\n              name,\n              path: fullPath,\n              variables: extractVariables(content, this.options.delimiters),\n            });\n          }\n        }\n      } catch {\n        // Directory doesn't exist\n      }\n    };\n\n    await scanDir(this.templateDir);\n    if (this.customTemplateDir) {\n      await scanDir(this.customTemplateDir);\n    }\n\n    return templates;\n  }\n\n  /**\n   * Generate content for a document type using built-in templates\n   * Fallback when no external template file exists\n   */\n  generateBuiltInContent(docType: string, title: string): string {\n    // Extracted from migration/worker.ts lines 659-696\n    const templates: Record<string, string> = {\n      readme: `# ${title}\\n\\n> TODO: Add project description\\n\\n## Overview\\n\\n## Getting Started\\n\\n## Usage\\n`,\n      guide: `# ${title}\\n\\n> TODO: Add guide introduction\\n\\n## Prerequisites\\n\\n## Steps\\n\\n### Step 1\\n\\n### Step 2\\n\\n## Summary\\n`,\n      'guide-user': `# ${title}\\n\\n> TODO: Add guide introduction\\n\\n## Prerequisites\\n\\n## Steps\\n\\n### Step 1\\n\\n### Step 2\\n\\n## Summary\\n`,\n      'guide-developer': `# ${title}\\n\\n> TODO: Add guide introduction\\n\\n## Prerequisites\\n\\n## Steps\\n\\n### Step 1\\n\\n### Step 2\\n\\n## Summary\\n`,\n      adr: `# ${title}\\n\\n## Status\\n\\nProposed\\n\\n## Context\\n\\n> TODO: Describe the context and problem\\n\\n## Decision\\n\\n> TODO: Describe the decision\\n\\n## Consequences\\n\\n> TODO: Describe the consequences\\n`,\n      spec: `# ${title}\\n\\n## Overview\\n\\n> TODO: Add specification overview\\n\\n## Requirements\\n\\n## Specification\\n\\n## Examples\\n`,\n      specification: `# ${title}\\n\\n## Overview\\n\\n> TODO: Add specification overview\\n\\n## Requirements\\n\\n## Specification\\n\\n## Examples\\n`,\n      changelog: `# Changelog\\n\\nAll notable changes to this project will be documented in this file.\\n\\n## [Unreleased]\\n\\n### Added\\n\\n### Changed\\n\\n### Fixed\\n`,\n      todo: `# TODO\\n\\nTasks and action items for this project.\\n\\n## High Priority\\n\\n## Medium Priority\\n\\n## Low Priority\\n`,\n      issues: `# Issues\\n\\nKnown issues and bugs.\\n\\n## Open Issues\\n\\n## Resolved Issues\\n`,\n      api: `# ${title}\\n\\n## Overview\\n\\n> TODO: Add API overview\\n\\n## Endpoints\\n\\n## Authentication\\n\\n## Examples\\n`,\n      'api-reference': `# ${title}\\n\\n## Overview\\n\\n> TODO: Add API overview\\n\\n## Endpoints\\n\\n## Authentication\\n\\n## Examples\\n`,\n      architecture: `# ${title}\\n\\n## Overview\\n\\n> TODO: Add architecture overview\\n\\n## Components\\n\\n## Interactions\\n\\n## Design Decisions\\n`,\n      'design-doc': `# ${title}\\n\\n## Overview\\n\\n> TODO: Add architecture overview\\n\\n## Components\\n\\n## Interactions\\n\\n## Design Decisions\\n`,\n    };\n\n    return templates[docType] ?? `# ${title}\\n\\n> TODO: Add content\\n`;\n  }\n\n  /**\n   * Clear the template cache\n   */\n  clearCache(): void {\n    this.templateCache.clear();\n  }\n\n  private resolveTemplatePath(dir: string, templateName: string): string {\n    // Try with .template.md extension first, then .md\n    const withTemplateExt = path.join(dir, `${templateName}.template.md`);\n    const withMdExt = path.join(dir, `${templateName}.md`);\n    // Will throw if neither exists - handled by caller\n    return withTemplateExt;\n  }\n}\n```\n\n### Step 4: Implement Template Processor (`processor.ts`)\n\n```typescript\nimport type { TemplateVariables, TemplateProcessorOptions, ProcessedTemplate } from './types.js';\n\n/**\n * Process a template string with variable substitution\n * \n * @param template - Template content with {{VAR}} placeholders\n * @param variables - Key-value pairs for substitution\n * @param options - Processing options\n * @returns ProcessedTemplate with content and variable tracking\n * \n * @example\n * ```typescript\n * const result = processTemplate(\n *   '# {{PROJECT_NAME}}\\n{{DESCRIPTION}}',\n *   { PROJECT_NAME: 'My Project', DESCRIPTION: 'A great project' }\n * );\n * // result.content = '# My Project\\nA great project'\n * ```\n */\nexport function processTemplate(\n  template: string,\n  variables: TemplateVariables,\n  options?: TemplateProcessorOptions\n): ProcessedTemplate {\n  const [openDelim, closeDelim] = options?.delimiters ?? ['{{', '}}'];\n  const strict = options?.strict ?? false;\n  const defaults = options?.defaults ?? {};\n  \n  // Merge defaults with provided variables\n  const mergedVars = { ...defaults, ...variables };\n  \n  const usedVariables: string[] = [];\n  const missingVariables: string[] = [];\n  \n  // Build regex to match placeholders\n  const escapedOpen = escapeRegex(openDelim);\n  const escapedClose = escapeRegex(closeDelim);\n  const regex = new RegExp(`${escapedOpen}([A-Z_][A-Z0-9_]*)${escapedClose}`, 'g');\n  \n  const content = template.replace(regex, (match, varName) => {\n    if (varName in mergedVars && mergedVars[varName] !== undefined) {\n      usedVariables.push(varName);\n      return String(mergedVars[varName]);\n    } else {\n      missingVariables.push(varName);\n      if (strict) {\n        throw new Error(`Missing template variable: ${varName}`);\n      }\n      return match; // Leave placeholder intact\n    }\n  });\n  \n  return { content, usedVariables, missingVariables };\n}\n\n/**\n * Extract all variable names from a template\n */\nexport function extractVariables(\n  template: string,\n  delimiters?: [string, string]\n): string[] {\n  const [openDelim, closeDelim] = delimiters ?? ['{{', '}}'];\n  const escapedOpen = escapeRegex(openDelim);\n  const escapedClose = escapeRegex(closeDelim);\n  const regex = new RegExp(`${escapedOpen}([A-Z_][A-Z0-9_]*)${escapedClose}`, 'g');\n  \n  const variables = new Set<string>();\n  let match;\n  while ((match = regex.exec(template)) !== null) {\n    variables.add(match[1]);\n  }\n  \n  return Array.from(variables);\n}\n\n/**\n * Create a template from content by replacing values with placeholders\n */\nexport function createTemplate(\n  content: string,\n  replacements: Record<string, string>,\n  delimiters?: [string, string]\n): string {\n  const [openDelim, closeDelim] = delimiters ?? ['{{', '}}'];\n  let template = content;\n  \n  for (const [varName, value] of Object.entries(replacements)) {\n    template = template.replace(new RegExp(escapeRegex(value), 'g'), `${openDelim}${varName}${closeDelim}`);\n  }\n  \n  return template;\n}\n\nfunction escapeRegex(str: string): string {\n  return str.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\n```\n\n### Step 5: Create Public API (`index.ts`)\n\n```typescript\n// Types\nexport type {\n  TemplateVariables,\n  TemplateProcessorOptions,\n  ProcessedTemplate,\n  TemplateInfo,\n  BuiltInTemplateName,\n} from './types.js';\n\n// Classes\nexport { TemplateManager } from './manager.js';\n\n// Functions\nexport {\n  processTemplate,\n  extractVariables,\n  createTemplate,\n} from './processor.js';\n```\n\n### Step 6: Update pkf-core Package Exports\n\nAdd to `packages/pkf-core/package.json`:\n\n```json\n{\n  \"exports\": {\n    \"./templates\": {\n      \"import\": \"./dist/templates/index.js\",\n      \"types\": \"./dist/templates/index.d.ts\"\n    }\n  }\n}\n```\n\n### Step 7: Update pkf-init to Use pkf-core/templates\n\n**`migration/worker.ts`:**\n```typescript\n// Before:\nprivate generateInitialContent(docType: string, title: string): string {\n  switch (docType) {\n    case 'readme': return `# ${title}...`;\n    // ... 14 cases\n  }\n}\n\n// After:\nimport { TemplateManager } from '@pantheon-tech/pkf-core/templates';\n\nprivate templateManager = new TemplateManager();\n\nprivate generateInitialContent(docType: string, title: string): string {\n  return this.templateManager.generateBuiltInContent(docType, title);\n}\n```\n\n**`generators/registers.ts`:**\n```typescript\n// Before: Hardcoded createTodo(), createIssues(), createChangelog() methods\n// After: Use TemplateManager with custom templates\nimport { TemplateManager, processTemplate } from '@pantheon-tech/pkf-core/templates';\n```\n\n### Step 8: Write Comprehensive Unit Tests\n\nCreate `packages/pkf-core/tests/templates/`:\n\n```typescript\n// processor.test.ts\ndescribe('processTemplate', () => {\n  it('should substitute single variable', () => {\n    const result = processTemplate('Hello {{NAME}}!', { NAME: 'World' });\n    expect(result.content).toBe('Hello World!');\n    expect(result.usedVariables).toEqual(['NAME']);\n    expect(result.missingVariables).toEqual([]);\n  });\n\n  it('should handle multiple variables', () => {\n    const template = '{{GREETING}} {{NAME}}, welcome to {{PLACE}}!';\n    const result = processTemplate(template, {\n      GREETING: 'Hello',\n      NAME: 'Developer',\n      PLACE: 'PKF'\n    });\n    expect(result.content).toBe('Hello Developer, welcome to PKF!');\n  });\n\n  it('should track missing variables', () => {\n    const result = processTemplate('{{KNOWN}} and {{UNKNOWN}}', { KNOWN: 'value' });\n    expect(result.missingVariables).toEqual(['UNKNOWN']);\n  });\n\n  it('should throw in strict mode for missing variables', () => {\n    expect(() => {\n      processTemplate('{{MISSING}}', {}, { strict: true });\n    }).toThrow('Missing template variable: MISSING');\n  });\n\n  it('should support custom delimiters', () => {\n    const result = processTemplate('Hello [[NAME]]!', { NAME: 'World' }, {\n      delimiters: ['[[', ']]']\n    });\n    expect(result.content).toBe('Hello World!');\n  });\n});\n\n// manager.test.ts\ndescribe('TemplateManager', () => {\n  it('should load template from directory');\n  it('should cache loaded templates');\n  it('should prefer custom templates over defaults');\n  it('should list available templates');\n  it('should generate built-in content for known doc types');\n  it('should return generic content for unknown doc types');\n});\n\n// extractVariables.test.ts\ndescribe('extractVariables', () => {\n  it('should extract all variable names from template');\n  it('should deduplicate repeated variables');\n  it('should handle templates with no variables');\n});\n```\n\nTarget: 90%+ test coverage.\n\n## Key Exports\n\n| Export | Type | Purpose |\n|--------|------|---------|\n| `TemplateManager` | class | Load and process template files |\n| `processTemplate()` | function | Substitute variables in template string |\n| `extractVariables()` | function | Get variable names from template |\n| `createTemplate()` | function | Convert content to template with placeholders |\n| `TemplateVariables` | type | Variable map for substitution |\n| `ProcessedTemplate` | type | Result with content and variable tracking |\n| `TemplateInfo` | type | Metadata about a template file |\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/pkf-core/src/templates/types.ts` | Create type definitions |\n| `packages/pkf-core/src/templates/processor.ts` | Create processor functions |\n| `packages/pkf-core/src/templates/manager.ts` | Create TemplateManager class |\n| `packages/pkf-core/src/templates/index.ts` | Create public exports |\n| `packages/pkf-core/package.json` | Add templates subpath export |\n| `packages/pkf-core/tests/templates/*.test.ts` | Create unit tests |\n| `packages/pkf-init/src/migration/worker.ts` | Update to use pkf-core/templates |\n| `packages/pkf-init/src/generators/registers.ts` | Update to use pkf-core/templates |\n\n## Integration with Existing Templates\n\nThe PKF repository already has 13 template files at `/templates/` using `{{PLACEHOLDER}}` syntax. The TemplateManager should:\n\n1. Support loading these files via `templateDir` option\n2. Use the same `{{VAR_NAME}}` delimiter pattern\n3. Provide fallback built-in templates when files aren't available\n\n## Notes\n\n- Task 15 \"Externalize Template Strings\" becomes partially addressed by this extraction\n- The `{{PLACEHOLDER}}` pattern matches existing templates (README.template.md, CLAUDE.template.md)\n- Built-in templates extracted from migration/worker.ts lines 659-696 serve as fallbacks\n- Template caching improves performance for repeated processing",
        "testStrategy": "## Verification Strategy\n\n### 1. Unit Test Coverage (pkf-core)\n- [ ] Run `npm test -- --coverage` in pkf-core and verify 90%+ coverage for templates module\n- [ ] Verify all public exports are tested:\n  - `TemplateManager` class: `loadTemplate()`, `process()`, `getAvailableTemplates()`, `generateBuiltInContent()`, `clearCache()`\n  - `processTemplate()` function with various inputs\n  - `extractVariables()` function\n  - `createTemplate()` function\n- [ ] Test edge cases:\n  - Empty templates\n  - Templates with no variables\n  - Deeply nested variable patterns\n  - Special characters in variable names\n  - Custom delimiters\n\n### 2. Template Processing Verification\n- [ ] Test `{{VAR_NAME}}` pattern matches existing PKF templates\n- [ ] Verify variable substitution is complete (no partial replacements)\n- [ ] Test strict mode throws on missing variables\n- [ ] Test non-strict mode preserves placeholders for missing variables\n- [ ] Verify `usedVariables` and `missingVariables` tracking is accurate\n\n### 3. TemplateManager Functionality\n- [ ] Test loading from default template directory\n- [ ] Test custom template directory override\n- [ ] Verify template caching works (second load is from cache)\n- [ ] Test `clearCache()` invalidates cached templates\n- [ ] Test `getAvailableTemplates()` scans directories correctly\n- [ ] Test built-in content generation for all 14 document types\n\n### 4. Integration Testing with pkf-init\n- [ ] Run `npm test` in pkf-init and verify all existing tests pass\n- [ ] Verify migration worker creates files with correct content\n- [ ] Test register initialization produces expected TODO.md, ISSUES.md, CHANGELOG.md\n- [ ] Confirm no regressions in file content generation\n\n### 5. Build Verification\n- [ ] Run `npm run build` in pkf-core - verify no TypeScript errors\n- [ ] Run `npm run build` in pkf-init - verify no TypeScript errors\n- [ ] Verify exports are accessible:\n  ```typescript\n  import { TemplateManager, processTemplate } from '@pantheon-tech/pkf-core/templates';\n  import type { TemplateVariables, ProcessedTemplate } from '@pantheon-tech/pkf-core/templates';\n  ```\n\n### 6. Compatibility with Existing Templates\n- [ ] Load `/templates/README.template.md` and extract variables\n- [ ] Verify variable list matches expected (PROJECT_NAME, DESCRIPTION, etc.)\n- [ ] Process template with test variables and verify output\n- [ ] Test all 13 existing template files load correctly\n\n### 7. Documentation Verification\n- [ ] All public exports have JSDoc comments\n- [ ] JSDoc includes @param, @returns, and @example tags\n- [ ] README.md in pkf-core documents templates module usage\n\n### 8. Regression Testing\n- [ ] Create test file that uses all template exports\n- [ ] Compare generated content with original pkf-init output for:\n  - README generation\n  - Guide generation\n  - ADR generation\n  - Changelog generation\n  - Register files generation\n- [ ] Verify frontmatter generation in migration worker still works",
        "status": "done",
        "dependencies": [
          "24"
        ],
        "priority": "high",
        "subtasks": [],
        "updatedAt": "2026-01-05T06:51:33.296Z"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-05T06:51:33.297Z",
      "taskCount": 15,
      "completedCount": 15,
      "tags": [
        "master"
      ]
    }
  }
}